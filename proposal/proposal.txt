Previous games such as Go considered in this course are two-player, deterministic zero-sum games. On the other hand, Hanabi occurs in a multiplayer setting where players form a grand coalition. They each have partial information and must collaborate to achieve the highest overall score possible. The initial states, or the cards the players start with, will differ from game to game. In addition, there is a probabilistic aspect because of the order in which players draw new cards from the deck. Some initial states are much easier to win from than others, usually when lower-numbered cards are drawn earlier because they must be played first. 
Instead of having a board with moving pieces, we instead have a large decision space where each player can choose one of three types of moves, which in turn heavily affects other players' actions in a complex manner. Each decision is constrained by the available resources, in this case information. For example, giving hints uses up information tokens and discarding cards removes valuable cards from play permanently. If players don't have enough information about their cards and there aren't enough information tokens available, they will be forced to guess at a card to play or discard a card. The former option has a probability of being incorrect, which uses up flare tokens and brings the game closer to an end. Both options can be harmful because a player could discard the only "5" of a suit, instantly lowering the highest possible score by 5, or discard a card other players need to play their own cards. The goal will be distributing and managing information well amongst players through the hinting process in order to maximize score. On a high level, this would involve giving hints which confer the most information and discarding cards with least utility while accounting for different initial states and different deck orders. To do this, we first need to be able to represent any given situation in the game as a state, each possible decision as an action, and formulate a reward, which is not trivial given the complexity of the game. 

Quantifying information for each hint will be difficult. A hint not only gives information of what cards a player has, but also includes negative information about what cards the player doesn't have. The hint also affects the information other players have because a player hinting another player is always with the intent of playing a card in the long-run, which gives some information to the non-hinted players of how their cards may be played. This gives rise to established metastrategies in human players, such as "finesse", which operate on negative information. For example, if a human player doesn't have valuable information on his cards or hints to give, he will default to discarding the oldest unplayed, unhinted card. The idea is that because it was unhinted, other players saw that it wasn't worth giving information about and can be eventually discarded. In a "finesse", imagine that a player sees that there is a white "1" on the table, the player after him has a white "2" as his rightmost card, and the third player after that has a white "3" of the same color. The player will then hint the third player of the "3". The second player will see the "1" already in play and the "3" the other player his, then assume he has the "2" as his rightmost card, which he then plays. A "finesse" has a high amount of information transferred through a hint because it affects two players, but relies on a complex network of decisions. 

Our primary research goal is writing a Hanabi bot which can consistently score above some threshold, as high as the full score of 25 as possible. We will also determine how well the bot performs with different numbers of information tokens and different numbers of players, which impact the information resources and decision space available. We will also determine how well the bot performs with different starting rules. For example, we could hard-code discarding the oldest unhinted card as a baseline instead of allowing the bot to learn it without any initial assumptions. It will be interesting to see if a trained bot will be able to replicate the metastrategies employed by human players, which maximize information value per hint. 
